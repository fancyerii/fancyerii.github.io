---
layout:     post
title:      "WFST Decoder Paper"
author:     "lili"
mathjax: true
excerpt_separator: <!--more-->
tags:
    - 人工智能
    - 语音识别
    - WFST
    - Decoder
---


 <!--more-->
 
**目录**
* TOC
{:toc}

## Chapter 4 WFST-based Modeling

### 语言模型G
#### 简介

n-gram语言模型很容易使用WFSA(也可以认为输出和输入一样的WFST)来表示，如下图所示，每个状态表示n-gram的所有可能的history h。比如$q_{uv}$表示3-gram的history是$uv$，状态$q_{uv}$到$q_{vw_1}$有一条边，输入label是$w_1$，边上的weight(概率)是$p(w_1 \vert uv)$。注意：原来的history是uv，输入w后新的history就变成了vw了。用形式化的语言描述就是：状态$q_h$遇到输入w后会进入状态$q_{\bar{h}w}$并且概率(weight)是$p(w \vert h)$。这里$\bar{h}$是去掉最前面的那个符号。比如当前状态是$q_h=q_{uv}$的时候，输入是$w_1$，那么就进入新的状态$q_{\bar{h}w}=q_{vw_1}$并且weight是$p(w_1 \vert uv)$。

这种表示方法非常简单，但是对于n-gram来说它有$\vert V \vert ^{n-1}$个点和$\vert V \vert ^n$条边，这里$\vert V \vert$代表词典的大小(词的个数)。这是非常大的，因此我们会介绍更加紧凑的表示方法，当然除了静态的方法之外，我们也可以在解码的时候on-the-fly的构造这个WFSA。下面我们介绍紧凑的表示方法。

 
<a name='f1'>![](/img/wfst-paper/1.png)</a>
*图：语言模型WFSA G*

#### 紧凑的表示法
我们首先简单的回顾一下有回退的语言模型的表示方法。更多语言模型的内容请参考[语言模型教程]({{ site.baseurl }}/books/lm)。

$$
p(w|h)=\begin{cases}\alpha(w,h) \text{ 当 } N(w,h)>0 \\
\gamma(h)p(w|\bar{h}) \text{其它}
\end{cases}
$$

对于在训练数据中出现过的n-gram $hw$来说，我们可以估计它的概率，然后打一些折扣，把多出来的概率用于没见过的n-gram。我们把这些的概率记为$\gamma(h)$。比如n-gram $hw'$没有出现过($N(w,h')=0$)，那么如果没有平滑的话其概率是0，现在从$\gamma(h)$里分一些概率给$hw'$，分的依据是$p(w \vert \bar{h} )$，当然这是一个递归的定义，直到$\bar{h}$是空，也就变成了p(w)，这个概率一定是大于零的(我们假设没有未登录词或者把未登录词都变成了特殊的UNK等)。

紧凑的表示方法只保存训练数据中出现过的状态和跳转(边)，除此之外对于长度小于n的history h会有一个状态，它用来表示那些打折的用于分配给没见过的n-gram的概率(也就是回退/backoff)。对于训练数据中见过的n-gram $hw$(显然$N(h,w)>0$)，都对于如下的一条边：

<a name='eq_1'></a>
$$
(q_h, w, \alpha(w,h),q_{h'}) \text{   其中} h'=\begin{cases} hw \text{ 如果 } |hw| < n \\
\bar{h}w \text{ 其它}
\end{cases}
$$

而回退用ε-跳转来表示，具体为$(q_h, \epsilon, \gamma(h),q_{\bar{h}})$。每个状态$q_h$都有一个ε-跳转的边，边的概率是$\gamma(h)$。下图是一个示例。

 
<a name='f2'>![](/img/wfst-paper/2.png)</a>
*图：语言模型WFSA G的紧凑表示*


上图中$N(w,uv)>0$，因此从状态$q_{uv}$有一条边到达$q_{vw}$，并且weight是$\alpha(w,uv)$(这是打折后的3-gram概率$p(w \vert uv)$)。

状态$q_{uv}$有一条ε-跳转的边到$q_v$，weight是$\gamma(uv)$。而状态$q_v$遇到输入w后又达到$q_{vw}$，weight是$\alpha(w,v)$(这是2-gram概率$p(w \vert v)$)。

状态$q_v$有一条ε-跳转的边到$q_{\epsilon}$, weight是$\gamma(v)$。状态$q_{\epsilon}$遇到输入w后到达$q_{w}$, weight是$\alpha(w)$(这是1-gram概率p(w))。

关于ε-跳转可能有些难以理解，我们下面通过一个例子来说明它。比如我们现在要计算概率$p(w'\vert uv)$，显然3-gram uvw'没有出现过，因此根据<a href='#eq_1'>上式</a>，我们需要回退到概率$\gamma(uv) \times p(w' \vert v)$。因此我们在上面的WFSA里首先沿着ε-跳转从状态$q_{uv}$到达$q_v$并且把权重$\gamma(uv)$累计进来。接着遇到输入w'，进入状态$q_{vw'}$，并且概率是$\gamma(w',v)=p(w' \vert v)$。


但是注意：上面的表示方法对于存在的n-gram会有多条边，比如$p(w \vert uv)$在上面的WFSA里有两条路径：一条路径是$uv->vw$；另一条是$uv -> v -> vw$。正确的应该只要第一条路径。这样计算出来的概率会比实际的要大。不过通常第二条路径的值很小(回退的概率)，而且如果是热带(tropical)半环的话，它是类似Viterbi解码，选择概率大的那个，因此第二条路径会被忽略。即使是log半环，因为第二条路径很小，把它加进去也不是太大的问题。

当然也存在更加精确的紧凑的表示方法，但是这会变得复杂，因此实际中我们通常使用这种有一点点误差的紧凑表示方法。使用紧凑的表示方法可以大大的减少WFSA中点和边的个数，比如大小为150K的词典上的4-gram的对比实验为：

 
<a name='f3'>![](/img/wfst-paper/3.png)</a>
*图：语言模型WFSA G的紧凑表示和非紧凑表示的对比*

从上表我们看出紧凑的表示方法确实很有效。

#### 句子的边界(Boundary)

大多数语言模型都会有句子的边界，也就是句子的开始也介绍，通常用两个特殊符号\<s>和\</s>来表示。在G中，我们可以用开始状态来表示\<s>，也就是$q_{\<s>}$是初始状态。这个初始状态只能有跳出去的边而不能有进入的边。这样要求我们识别的语音是做个句子切分的，但是有的场合要求我们识别的不是完整的句子，比如是句子1的后半部分和句子2的前半部分。那么在这种常见下就必须有从结束状态跳入初始状态的边了。后面第八章会讨论这个问题，我们这里先假设输入是完整的句子(utterance)。

对于句子的结束有两种处理方法。第一种是把符号\</s>看成一个普通的符号(词)，并且对于这个输入都跳到一个特殊的结束状态，也就是$(q_h, \</s>, p(\</s> \vert h), q_{\</s>})$。在WFSA里只有一个结束状态，那就是$q_{\</s>}$。使用这种表示法的一个示例WFSA如下图所示。

 
<a name='f4'>![](/img/wfst-paper/4.png)</a>
*图：显示的句子结束表示*

另外一种表示方法是把句子结束的概率编码到结束状态的weight里，这种方法\</s>不需要出现在WFSA里，并且它会有很多结束状态(理论上任何一个词都有一定概率结束)。使用这种方法时，解码器发现某个状态结束时(后面没有要解码的内容了)需要把这个状态的weight加上。

如果句子结束是使用第一种方法显示表示，因为L(Lexicon)是定义词有哪些音素组成，显然句子结束是没有真正的声音的，所以通常在WFST L里可以把\</s>映射成ε、silence或者一个特殊的音素。

#### 输入Label

G的输入可以是词或者词的发音变体(pronunciation variants)的ID。发音变体指的是一个词有多个发音，比如read可以发音成/r/i/d/和/r/ɛ/d/。我们可以把这两个"read"记作"read#1"和"read#2"，在L中它们对应不同的音素。为了表示发音变体，我们可以引入一个WFST P，它只有一个状态q，并且边为$((q, v, w, p(v \vert w), q)$，这里w是词，比如read，而v是发音变体比如read\#1，$$p(v \vert w)=p(read\#1 \vert read)$$是read发第一种因的概率。我们把L和G组合(composite)起来得到$L \circ G$，它的输入是发音变体的序列，输出是词的序列。

通常我们的G的输入都是词，但是使用发音变体的作用是解码后我们可以知道这个词的发音。如果词的发音变体较多，则组合后的WFST会大很多。对于英语来说平均每个词有1.2个发音变体，这还问题不大，最终的WFST只是增加了20%的空间。但是对于阿拉伯语言，每个词的平均发音变体有3.5个，这将极大的增加WFST的空间。比如下图是两种语言使用发音变体前后的对比，我们可以看到对于阿拉伯语来说，WFST的边数是之前的3.5倍。

 
<a name='f5'>![](/img/wfst-paper/5.png)</a>
*图：发音变体对WFST大小的影响*



### 发音词典L

#### 简介

L是发音词典，它的输入是phone输出是词，更具体的说它的输入是上下文无关的音素序列(CI phonemes)，输出是词序列。如果G要求的输入是词的发音变体，则L的输出也有变成词的发音变体。发音词典的每个词都可以转换成一个WFST，然后我们使用Kleene闭包来把多个词Union起来从而可以识别多个词。


因为存在两个(甚至多个)词的发音相同，从而使得L无法确定化(determinization)。比如"read"和"red"的发音是相同的。此外，即使没有两个词发音相同，L仍然是无法确定化的，原因是unbound输出延迟。如果整个音素序列都必须扫描完成才能确定输出的序列，则就存在unbound输出延迟。当音素之间存在前缀包含关系的时候就有unbound输出延迟，比如下图的例子：

<a name='f7'>![](/img/wfst-paper/7.png)</a>
*图：不能确定化的L的例子*

上面这个例子很简单：它只识别两个词a和AA。它们的发音分别是[ey]和[ey ey]，AA的发音包含a。这这个例子里，我们看到/ey/的时候并不能确定它是a还是AA，如果后面没有。如果后面没有了，那么就应该识别成a，如果后面还有/ey/则识别成AA。(当然其它的不能识别或者说识别失败)

为了解决这个问题，我们会引入特殊的消歧符号，比如#1、#2，来表示词的结束。一般我们用#1来表示一个词的结束音素，但是如果有多个词的发音相同，那么就需要#2或者#3来表示不同的词。下图是一个示例的L：

<a name='f6'>![](/img/wfst-paper/6.png)</a>
*图：未确定的L的示例*


上图的L是非确定的，它的构造非常简单。对于发音词典里的每一个词，比如"books b uh k s #1"，它表示"books"的发音是/b/uh/k/s/。则我们可以这样构造WFST：它有一个唯一的初始状态，也是接受状态(图中两个圈的状态)，有一条边的输入是"b"，输出是"books"。也就是说它看到输入音素"b"，就猜测输出是词"books"(不熟悉的读者请参考[WFST简介]({{ site.baseurl }}/books/wfst))。接下来的状态就是一个链条，它只能接受"uh k s #1"并且回到初始/接受状态，并且这个链条上的每条边的输出是空(ε)。读者可能会问，那如果真实的输入是"b ae d #1"(bad)呢？没问题，因这个WFST是非确定的，就行非确定的FSA，它会同时"模拟"多条可能路径，因此当看到"b"时，它会同时进入"books"、"book"和"bad"这三条路径的下一个状态，当遇到第二个输入"ae"的时候，前两条路径都走不了，因此只能继续走"bad"的那条路径。

另外如果多个词的发音相同的话，比如"read"和"red"都发音为/r/eh/d/，则我们需要把一个变成"r eh d #1"而另一个变成"r eh d #2"。如果还有相同的发音那就需要#3、#4……。

加入了消歧符号之后，我们就可以对L进行确定化和最小化操作了。对<a href='#f6'>上图</a>进行确定化的结果如下图所示：

<a name='f8'>![](/img/wfst-paper/8.png)</a>
*图：det(L)*

我们可以看到，确定化把输出往后推迟了。比如遇到输入b的时候并不输出(因为有"books"、"book"和"bad"三种可能)，接着输入ae的时候只有一种可能了就输出"bad"。类似的，如果b后是uh仍然不能输出(因为有"books"和"book")，再接着输入是k仍然不能输出，直到遇到s或者#1，这就能判定是"books"还是"book"了。从另一个角度来说确定化把相同的前缀做了合并。

L确定化后我们还可以对它进行最小化操作，结果如下图所示：

<a name='f9'>![](/img/wfst-paper/9.png)</a>
*图：min(det(L))*

把min(det(L))和det(L)相比，我们会发现最小化把相同的状态合并了。比如"books"、"bad"和"read[r iy d]"都是没有歧义的，可以把它们的最后一个状态合并在一起，这个合并的状态只接受#1然后回到初始状态。同理，我们可以把"read[r eh d]"和"red"的最后一个状态合并，它碰到#1输出read碰到#2输出red。


对L进行确定化和最小化可以极大的减少WFST的大小，下表是实验的对比结果：


<a name='f10'>![](/img/wfst-paper/10.png)</a>
*图：确定化和最小化对L的影响*



#### 发音变体(Pronunciation Variants)

根据G的要求，L的输出可以是词也可以是词的发音变体。此外，从音素到词的Transducer可能有权重(比如read发音成/r eh d/和/r ih d/的概率是不同的，如果这个概率没有整合到G中就必须放到L中)。

前面我们介绍过，可以使用发音变体到词的Transducer P。我们通过$L \circ P$就可以把发音变体序列映射成词序列并且同时整合上权重。$L \circ P$的复合操作可以在对L确定化和最小化操作之后进行，也就是$min(det(L)) \circ P$；也在它之前进行，也就是$min(det(L \circ P))$。


如果发音的概率(权重)在确定化和最小化之前引入，那么确定化和最小化需要对无权重的Transducer进行操作(也就是把权重和输出放到一起)。否则发音权重的重新分配(redistributing)会对搜索的剪枝(pruning)带来负面影响，原因是$L \circ P$不是概率的(stochastic)，也就是出边的和不是$\bar{1}$。如果把权重和输入放到一起的话，则会妨碍前缀的合并(前面介绍L的确定化的主要用途)。

对于$L \circ P$进行确定化和最小化可以更大程度的合并前缀与后缀，从而可以使得WFST更小。实验结果如下表所示：



<a name='f11'>![](/img/wfst-paper/11.png)</a>
*图：对$L \circ P$进行确定化和最小化*

从上表可以看到，对于英语来说(发音变体不多)，先复合后再优化(确定化和最小化)能减少8%的点和5%的边；而对于阿拉伯语来说，能减少53%的点和42%的边。


### 上下文相关的因子

声学模型通常是上下文相关的，也就是一个音素的发音是依赖于它周围的其它音素。实践中通常使用triphones模型，也就是一个音素依赖于它前后个一个音素。我们可以使用一个WFST C，它的输入是上下文相关的因子(context-dependent phones)，输出是上下文无关的因子(context-independent phones)。

C的作用是把一个上下文相关的(因子)符号序列转换成上下文无关的序列，下图是上下文相关和上下文无关序列的示例图。

<a name='f12'>![](/img/wfst-paper/12.png)</a>
*图：a)，上下文无关的(因子)符号序列；b)，上下文相关的(因子)符号序列*



为了进行上下文相关的映射，C的状态需要编码一个音素的上下文信息。因此最直接的方法就是对于每一对因子，都有一个状态来表示。比如在下图(a)中，对于triphone $_ab_c$(也有记为"a-b+c"或者"b/a_c")，可以从状态(a,b)跳到(b,c)。


<a name='f13'>![](/img/wfst-paper/13.png)</a>
*图：Transducer C的示例，a)，输出是不确定的；b)，输出是确定的*


在图(a)的WFST里，(a,b)表示已经读过符号a了，并且下一个要读的是b。因此这个状态的出边的中心因子一定是b，并且左边context一定是a。在这个例子中它有两条边$_ab_c$和$_ab_d$，分别进入状态(b,c)和(b,d)。这可能有些费解，我们再来"读"一遍：(a,b)表示已经读(处理)过a并且即将读b(这是类似NFA的猜测)，遇到$_ab_c$(运气不错，猜对了)就输出上下文无关的b，并且进入新的状态(b,c)，这个状态表示已经读过b并且猜测即将读取c。

但是这种表示方法的确定是：它的输出是不确定的(non-deterministic)。对于状态(a,b)，对于任何的triphone $_ab_c$，它的输出都是b。这样的C和L复合时会带来问题。假设L中的一个跳转(边)$e_L$，假设$i(e_L)=b$(也就是说这条边的输入符号是b)；并且假设C中有一个状态(a,b)。那么对于任意的$_ab_c$(也就是任意的c)，都会有复合出一条边e，这条边的的起点是$p[e] = ((a,b) , p[e_L])$，终点是$n[e] = ((b, c), n[e_L])$。但是这些边大部分都是死的，除非这个c是$n[e_L]$的输入符号，这样的c显然不会太多，所以上面的复合操作会产生大量无用的边。

如下图所示，我们假设L有一条的输入符号是b(输出不用care)，并且这条边的终点只能输入c和d。但是$C \circ L$就会复合出$_ab_a,_ab_b,_ab_c,_ab_d$，但是因为b后面只能有c和d，因此$_ab_a,_ab_b$其实是无用的结果。


<a name='f14'>![](/img/wfst-paper/14.png)</a>
*图：符号产生大量无用边的示例*


上面的问题就是输出不确定带来的，为了解决这个问题，我们可以使用<a href='#f13'>上图(b)</a>所示的表示方法。在这里，状态(a,b)表示a和b都已经读过了(b在这个状态之前已经输出过了)。比如图中的例子，在状态(a,b)时，输入是$_ab_c$，输出是c。输出提前了一个时刻，或者说输入的上下文相关因子比输出的上下文无关因子延迟了一个时刻。(a,b)在遇到$_ab_c$时的输出是c，因为遇到$_ab_c$，我们可以提前判断下一个输出一定是c，因此我们可以提前输出。

我们可以这样解读：状态(a,b)表示我们已经输出过了上下文无关符号a和b了，接着我们遇到$_ab_c$，因此我们可以输出c并且进入状态(b,c)。

上下文相关符号的延迟是在初始状态就开始了，初始状态的输入是ε，输出是第一个上下文无关的符号。为了消费(读取)掉最后一个triphone(对应的上下文无关phone已经提前输出过了)，C还需要最后一个特殊的输出符号。我们可以使用一个特殊的输出符号，那么这个符号就必须出现在发音词典L中(否则没法实现$C \circ L$)，比如我们可以把它作为句子结束符号的发音(句子结束符号是没有声音的)。我们也可以使用silence作为最后的输出。不管是哪种方法，$C \circ L$的最后一个输出都和输入的triphone序列没有任何对应关系。除了上面两种方法之外，还可以输出ε，但这有一个问题，它在与L复合时会产生失败的边。

如果L包含消歧符号，那么在C的每个状态都要增加Self loop，它的作用是把triphone的消歧符号映射成音素的消歧符号。

#### 词的边界(Word Boundary)

这篇文章使用的声学模型不仅考虑一个音素的上下文，同时也会考虑音素在词中的位置。位于词开始和结尾的triphone与位于词中间的triphone是不同的。为了生成与之匹配的上下文相关符号，L中每个词的第一个音素需要替换成增加了特殊tag的符号。词开始位置的音素a被替换成$a^i$。由于C输出的确定性，所以只需要tag开始的音素。

如下图所示，ab是一个词的音素，而cd是两一个词的音素。对于两个词的边界状态(b,c)，我们需要表示成$(b, c^i)$。从(a,b)到$(b, c^i)$跨越了词的边界，因此它接受的输入是$_ab^f_c$，表示当前的中心音素b是一个词的结束，因此输出是下一个时刻的$c^i$。接着下一个时刻的输入是$_bc^i_d$，它的输出就是普通的d了，并且进入普通的(c,d)状态。


<a name='f15'>![](/img/wfst-paper/15.png)</a>
*图：C中两个词的边界的跳转*

开始音素与左边的上下文是无关的。因此从状态$(b, c^i)$的边是进入(c,d)而不是$(c^i, d)$。

#### 跨词(Across-Word)的上下文依赖

为了更好的效果，现在的声学模型通常会考虑跨词的上下文依赖，当然如果有silence，那么就会导致左边或者右边的context是ε。silence和其它的非语音(non-speech比如咳嗽等等)使用上下文无关的伪音素(pseudo-phonemes)。把它们放到C里的方法如下图所示。


<a name='f16'>![](/img/wfst-paper/16.png)</a>
*图：C中的si(silence)*


图中的$$_ab_\#$$表示b是最后一个音素是b，它的输出是si，然后状态进入(#,si)而不是(b,#)，原因是si不需要左边的上下文。类似的下一个时刻的输入是$$_\#si_\#$$，输出是c，表示猜测下一个时刻的输入是c。
